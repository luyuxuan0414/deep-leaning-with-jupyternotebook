{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0120ca15",
   "metadata": {},
   "source": [
    "# A first look at a neural network\n",
    "Loading the MNIST dataset in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dee0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91010ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST 的例子中，樣本就是數字圖像\n",
    "from tensorflow.keras.datasets import mnist #為了要辨識0-9的手寫數字集，keras模組有提供資料集，此處先載入他們\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "#train_images包含了我們要訓練的圖片，train_labels是標籤，標記了對應的train_images是哪個數字\n",
    "#test_images、test_labels是最後用來驗證我們的模型使用，觀察一下資料集的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48c506ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape#(60000, 28, 28) -> 60000張，每張像素是28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a296fa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)#對應的標籤當然就也是60000張"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af8b4c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels#0~9的種類，共10種"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "68cb981e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da1c769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape# (10000, 28, 28) -> 10000張用來做為測試的圖像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "123ca1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)#10000 -> 對應的標籤當然是10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd0528eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels#0~9的種類，共10種"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec42a4cb",
   "metadata": {},
   "source": [
    "# The network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35012b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 15:49:46.007198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Sequential 可定義類神經網路中的圖層序列\n",
    "#Dense 加上一層神經元 ; Relu 有效表示，如果 X 大於 0，則傳回 0，否則傳回 0。只會將 0 以上的值傳送到網路中的下一層。\n",
    "#Softmax」採用一組值，因此可有效挑選出最大的值。例如，如果最後一個層的輸出看似像 [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05]\n",
    "#那後它可以避免您必須排序最大值——它返回 [0,0,0,0,1,0,0,0,0]。\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([#宣告順序層且建立模型\n",
    "    layers.Dense(512, activation=\"relu\"),#第一層layer，數字512代表有512個隱藏神經元（有512個輸出變數）（使用relu激勵函數）\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "    #在這邊代表第二層layer（最後一個Dense Layer）：輸出10個神經元，透過softmax activation(激勵函數)，轉成機率\n",
    "    #即0-9的預測機率，選擇最大機率者為預測值。\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29011f88",
   "metadata": {},
   "source": [
    "# The compilation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e307a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#編譯步驟\n",
    "model.compile(optimizer=\"rmsprop\",#確立目標及求解方法：以compile函數定義損失函數(loss)、優化函數(optimizer)及成效衡量指標(mertrics)\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed79359f",
   "metadata": {},
   "source": [
    "Preparing the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38874845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#為了方便訓練我們把圖片從28乘28的二維圖形轉換成1維長784的向量，然後將0~255的圖片，縮到0~1的範圍\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4908d5",
   "metadata": {},
   "source": [
    "\"Fitting\" the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7101ddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2606 - accuracy: 0.9251\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1047 - accuracy: 0.9688\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0702 - accuracy: 0.9786\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0510 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0375 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff6d00d6e90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
    "#使用model.fit進行訓練，train_images數字影像的特徵值，label數字影像真實的值。\n",
    "#model.fit 執行時，您會看到損失以及準確度\n",
    "#設定epoch(訓練週期)次數與每一批次比數 epoch=5：執行5次訓練週期 batch_size=128:每一批次128筆資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0cde7",
   "metadata": {},
   "source": [
    "Using the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c58029e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "#做實際預測\n",
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)#輸入為test sample 輸出為label\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa50355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0609823e-08, 2.3605842e-10, 2.9186999e-06, 1.3873537e-04,\n",
       "       1.1476746e-12, 3.0293066e-09, 6.2616817e-15, 9.9985027e-01,\n",
       "       3.8813713e-08, 7.9242445e-06], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b9566c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].argmax()#取得預測答案\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5348976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1].argmax()#取得預測答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23a5cd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998503"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ed312e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "beec0455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cb5ee",
   "metadata": {},
   "source": [
    "Evaluating the model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc1c088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.9761\n",
      "test_acc: 0.9761000275611877\n"
     ]
    }
   ],
   "source": [
    "#模型評估\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)#model.evaluate()測試模型->會回報每組的loss(損失)\n",
    "print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861cab2",
   "metadata": {},
   "source": [
    "# Data representations for neural networks\n",
    "Scalars (rank-0 tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "228a6daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b208526a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0a6db1",
   "metadata": {},
   "source": [
    "# Vectors (rank-1 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab3af94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14,  7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6492d566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim#維度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63244ab4",
   "metadata": {},
   "source": [
    "# Matrices (rank-2 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86f850dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c81804e",
   "metadata": {},
   "source": [
    "# Rank-3 and higher-rank tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03b14662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542b7aec",
   "metadata": {},
   "source": [
    "Key attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20cb8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c34405c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim#軸的個數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8845221e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape#形狀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91988869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype#數據類型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b70ad",
   "metadata": {},
   "source": [
    "Displaying the fourth digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecda3d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[1]#數字可改，更改後圖片都會不一樣（顯示第一個數字）\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()#圖像顯示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3a6b194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b64b680",
   "metadata": {},
   "source": [
    "# Manipulating tensors in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f887b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#操作向量\n",
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a973abc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#也是操作向量\n",
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8684b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#也是操作向量\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87738eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#一般來說，你可以沿著每個張量軸在任意兩個索引之間進行選擇。例如，你可以在所有圖像的右下角選出14 像素×14 像素的區域：\n",
    "my_slice = train_images[:, 14:, 14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfd8f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#也可以使用負數索引。與Python 列表中的負數索引類似，它表示與當前軸終點的相對位置。你可以在圖像中心裁剪出14 像素×14 像素的區域\n",
    "my_slice = train_images[:, 7:-7, 7:-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c183dd6",
   "metadata": {},
   "source": [
    "# The notion of data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf03e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#具體來看，下面是MNIST 數據集的一個批量，批量大小為128。\n",
    "batch = train_images[:128]#第一批"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50b1c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_images[128:256]#第二批"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c05dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]#第n批"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a6c6b",
   "metadata": {},
   "source": [
    "# Real-world examples of data tensors\n",
    "Vector data\n",
    "Timeseries data or sequence data\n",
    "Image data\n",
    "Video data\n",
    "The gears of neural networks: tensor operations\n",
    "Element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f246062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()#x是一個Numpy的2D張量 避免覆蓋輸入張量\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da8eaa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#兩個矩陣的加法\n",
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0fba8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.01 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b140928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20d9037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75715623 0.82214662 0.38163813 ... 0.24577263 0.45597196 0.42909988]\n",
      " [0.86990414 0.14976975 0.01229364 ... 0.23956509 0.84647322 0.67256423]\n",
      " [0.9548692  0.75610319 0.8729036  ... 0.07269524 0.51763604 0.97720142]\n",
      " ...\n",
      " [0.86335734 0.64896802 0.49323533 ... 0.26772854 0.44730095 0.22775695]\n",
      " [0.97399949 0.72494377 0.73841372 ... 0.20963234 0.43077198 0.87339872]\n",
      " [0.87891104 0.03590429 0.8583106  ... 0.81755135 0.94231038 0.66580508]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((32, 10))#隨機\n",
    "y = np.random.random((10,))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0970f054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85479994 0.86300136 0.07206236 0.07696391 0.55462597 0.90204085\n",
      " 0.32624849 0.9574974  0.05595674 0.63734409]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9cb5254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85479994 0.86300136 0.07206236 0.07696391 0.55462597 0.90204085\n",
      "  0.32624849 0.9574974  0.05595674 0.63734409]]\n"
     ]
    }
   ],
   "source": [
    "#np.expand_dims(arr, axis);arr：arr 為必填參數，為輸入數組。axis：要插入新軸的位置。\n",
    "y = np.expand_dims(y, axis=0)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc51062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85479994 0.86300136 0.07206236 0.07696391 0.55462597 0.90204085\n",
      "  0.32624849 0.9574974  0.05595674 0.63734409]]\n"
     ]
    }
   ],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)#np.concatenate()合併陣列\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c521902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):#矩陣和向量增加\n",
    "    assert len(x.shape) == 2 #x是Numpy的2D張量\n",
    "    assert len(y.shape) == 1 #y是一個Numpy的向量\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba87dcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.67128284 0.43549173 0.60057845 ... 0.91986013 0.82461148\n",
      "    0.3523511 ]\n",
      "   [0.57569954 0.61455119 0.9598142  ... 0.68837401 0.64894967\n",
      "    0.57058817]\n",
      "   [0.74684134 0.23826496 0.69303754 ... 0.85018038 0.86255839\n",
      "    0.55659487]\n",
      "   ...\n",
      "   [0.93867571 0.84880558 0.52746462 ... 0.99900876 0.93454992\n",
      "    0.40048526]\n",
      "   [0.84813525 0.63099565 0.40838229 ... 0.75297494 0.47507855\n",
      "    0.83022115]\n",
      "   [0.01201309 0.25043211 0.85819515 ... 0.91121127 0.92659656\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.94495261 0.42912152 0.60057845 ... 0.91986013 0.82705327\n",
      "    0.75663132]\n",
      "   [0.70021455 0.36247765 0.44434986 ... 0.68837401 0.46331493\n",
      "    0.99773246]\n",
      "   [0.46655263 0.35470498 0.42213779 ... 0.71624667 0.87545541\n",
      "    0.55659487]\n",
      "   ...\n",
      "   [0.93867571 0.48775851 0.40621687 ... 0.99900876 0.74135878\n",
      "    0.1123122 ]\n",
      "   [0.84813525 0.85039015 0.50802574 ... 0.75297494 0.9581098\n",
      "    0.3600414 ]\n",
      "   [0.90579115 0.31725721 0.70107587 ... 0.51179637 0.92659656\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.67128284 0.90572378 0.60057845 ... 0.91986013 0.82461148\n",
      "    0.29591387]\n",
      "   [0.4992253  0.64777497 0.53859592 ... 0.68837401 0.5423556\n",
      "    0.5615934 ]\n",
      "   [0.60084626 0.54051588 0.42213779 ... 0.71624667 0.56009592\n",
      "    0.84105223]\n",
      "   ...\n",
      "   [0.98723939 0.33679548 0.94297263 ... 0.99900876 0.71025402\n",
      "    0.19991449]\n",
      "   [0.84813525 0.60186708 0.12811316 ... 0.75297494 0.65108112\n",
      "    0.40081878]\n",
      "   [0.99242139 0.05522524 0.94773385 ... 0.51179637 0.92659656\n",
      "    0.82632233]]]\n",
      "\n",
      "\n",
      " [[[0.67128284 0.90557695 0.60057845 ... 0.91986013 0.82461148\n",
      "    0.88436528]\n",
      "   [0.69391053 0.36247765 0.35257076 ... 0.68837401 0.46331493\n",
      "    0.23950797]\n",
      "   [0.32514795 0.46730591 0.54434168 ... 0.71624667 0.64790299\n",
      "    0.55659487]\n",
      "   ...\n",
      "   [0.93867571 0.33679548 0.54785124 ... 0.99900876 0.71630566\n",
      "    0.18672744]\n",
      "   [0.84813525 0.08616734 0.32054145 ... 0.87170606 0.47507855\n",
      "    0.30614768]\n",
      "   [0.61216876 0.24949489 0.70107587 ... 0.51179637 0.92659656\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.6719979  0.90864261 0.60057845 ... 0.91986013 0.82461148\n",
      "    0.52804373]\n",
      "   [0.57254577 0.43942267 0.84466981 ... 0.68837401 0.81514867\n",
      "    0.6740078 ]\n",
      "   [0.98847173 0.64540484 0.78285541 ... 0.71624667 0.56009592\n",
      "    0.76985858]\n",
      "   ...\n",
      "   [0.93867571 0.33679548 0.6858193  ... 0.99900876 0.71971784\n",
      "    0.38576065]\n",
      "   [0.91906871 0.13804592 0.60591011 ... 0.75297494 0.51388149\n",
      "    0.30614768]\n",
      "   [0.47932875 0.66304131 0.70107587 ... 0.60185672 0.95422886\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.74499297 0.41459269 0.60057845 ... 0.91986013 0.82461148\n",
      "    0.93099295]\n",
      "   [0.4992253  0.36247765 0.35257076 ... 0.68837401 0.46331493\n",
      "    0.16914055]\n",
      "   [0.60724032 0.36305954 0.89153039 ... 0.71624667 0.56009592\n",
      "    0.55659487]\n",
      "   ...\n",
      "   [0.93867571 0.33679548 0.40621687 ... 0.99900876 0.71025402\n",
      "    0.78969205]\n",
      "   [0.84813525 0.640691   0.25555688 ... 0.75297494 0.47507855\n",
      "    0.6156987 ]\n",
      "   [0.80402133 0.23928629 0.70107587 ... 0.71309115 0.93849042\n",
      "    0.82632233]]]\n",
      "\n",
      "\n",
      " [[[0.71688727 0.17689613 0.60057845 ... 0.91986013 0.82461148\n",
      "    0.29591387]\n",
      "   [0.68615518 0.80310211 0.67250266 ... 0.68837401 0.46331493\n",
      "    0.75825094]\n",
      "   [0.41579724 0.32868355 0.62134166 ... 0.71624667 0.6874377\n",
      "    0.59819155]\n",
      "   ...\n",
      "   [0.93867571 0.73858002 0.69061954 ... 0.99900876 0.71025402\n",
      "    0.20737825]\n",
      "   [0.84813525 0.3414546  0.05711377 ... 0.75297494 0.60883937\n",
      "    0.792441  ]\n",
      "   [0.19561577 0.71842951 0.70107587 ... 0.56247086 0.92659656\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.67128284 0.38925374 0.85116629 ... 0.91986013 0.82461148\n",
      "    0.72764007]\n",
      "   [0.4992253  0.55581672 0.48036706 ... 0.87921484 0.60148498\n",
      "    0.57452261]\n",
      "   [0.32499123 0.59810205 0.67831313 ... 0.71624667 0.56009592\n",
      "    0.55659487]\n",
      "   ...\n",
      "   [0.93867571 0.33679548 0.40621687 ... 0.99900876 0.71025402\n",
      "    0.93609445]\n",
      "   [0.84813525 0.95288597 0.34961434 ... 0.80924886 0.84951045\n",
      "    0.30614768]\n",
      "   [0.5811409  0.14513712 0.70107587 ... 0.98926197 0.92659656\n",
      "    0.90930425]]\n",
      "\n",
      "  [[0.67128284 0.86108491 0.84410299 ... 0.91986013 0.82461148\n",
      "    0.33186134]\n",
      "   [0.4992253  0.97450373 0.35257076 ... 0.75596794 0.99056396\n",
      "    0.29715367]\n",
      "   [0.79238448 0.23826496 0.79685156 ... 0.71624667 0.56009592\n",
      "    0.55659487]\n",
      "   ...\n",
      "   [0.93867571 0.33679548 0.75971882 ... 0.99900876 0.71025402\n",
      "    0.67437731]\n",
      "   [0.84813525 0.08008616 0.51148018 ... 0.75297494 0.47507855\n",
      "    0.30614768]\n",
      "   [0.4220585  0.85440984 0.70107587 ... 0.51179637 0.92659656\n",
      "    0.84878862]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.67128284 0.21097289 0.87574276 ... 0.91986013 0.86519624\n",
      "    0.43567036]\n",
      "   [0.6360561  0.81469891 0.98819857 ... 0.68837401 0.46331493\n",
      "    0.15679338]\n",
      "   [0.86581489 0.23826496 0.97456631 ... 0.98376738 0.87969581\n",
      "    0.55659487]\n",
      "   ...\n",
      "   [0.93867571 0.72828505 0.81872541 ... 0.99900876 0.90183804\n",
      "    0.36131967]\n",
      "   [0.84813525 0.20315329 0.42625257 ... 0.75297494 0.98410977\n",
      "    0.90363767]\n",
      "   [0.45713383 0.32283898 0.70107587 ... 0.51179637 0.92659656\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.67128284 0.17689613 0.60057845 ... 0.91986013 0.82461148\n",
      "    0.29591387]\n",
      "   [0.4992253  0.94987791 0.91348949 ... 0.68837401 0.46331493\n",
      "    0.15679338]\n",
      "   [0.32499123 0.97543549 0.46580554 ... 0.71624667 0.72156571\n",
      "    0.55659487]\n",
      "   ...\n",
      "   [0.93867571 0.42186198 0.40621687 ... 0.99900876 0.81506061\n",
      "    0.59081789]\n",
      "   [0.84813525 0.65699853 0.72482715 ... 0.75297494 0.47507855\n",
      "    0.5719403 ]\n",
      "   [0.18940728 0.93018137 0.70107587 ... 0.81850461 0.92659656\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.67128284 0.94806168 0.97121392 ... 0.91986013 0.94540994\n",
      "    0.89532075]\n",
      "   [0.94009523 0.36247765 0.7649299  ... 0.68837401 0.46331493\n",
      "    0.95248845]\n",
      "   [0.83316566 0.47331774 0.76409089 ... 0.95930768 0.61532719\n",
      "    0.69964034]\n",
      "   ...\n",
      "   [0.9905347  0.50424947 0.40621687 ... 0.99900876 0.71025402\n",
      "    0.84083261]\n",
      "   [0.84813525 0.91392804 0.47104728 ... 0.75297494 0.88168031\n",
      "    0.63777204]\n",
      "   [0.01201309 0.53746177 0.70107587 ... 0.51179637 0.92659656\n",
      "    0.82632233]]]\n",
      "\n",
      "\n",
      " [[[0.67128284 0.83587803 0.80755622 ... 0.91986013 0.82461148\n",
      "    0.29591387]\n",
      "   [0.71695356 0.77682168 0.75237284 ... 0.68837401 0.46331493\n",
      "    0.37410263]\n",
      "   [0.67756926 0.33229927 0.85547616 ... 0.71624667 0.56009592\n",
      "    0.94042059]\n",
      "   ...\n",
      "   [0.93867571 0.93576448 0.40621687 ... 0.99900876 0.71025402\n",
      "    0.44735405]\n",
      "   [0.84813525 0.44142352 0.84047755 ... 0.75297494 0.47507855\n",
      "    0.30614768]\n",
      "   [0.65416693 0.7413093  0.87689541 ... 0.51179637 0.92659656\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.67128284 0.17689613 0.64535001 ... 0.94801162 0.82461148\n",
      "    0.50472818]\n",
      "   [0.4992253  0.52427601 0.35257076 ... 0.68837401 0.46331493\n",
      "    0.33876979]\n",
      "   [0.37893353 0.4519041  0.42213779 ... 0.71624667 0.56009592\n",
      "    0.57419999]\n",
      "   ...\n",
      "   [0.93867571 0.54285922 0.40621687 ... 0.99900876 0.71025402\n",
      "    0.71972754]\n",
      "   [0.84813525 0.51257998 0.72740891 ... 0.75297494 0.47507855\n",
      "    0.63170278]\n",
      "   [0.05017773 0.14753353 0.87936204 ... 0.92324109 0.92659656\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.67128284 0.56808424 0.78687372 ... 0.91986013 0.98780988\n",
      "    0.29591387]\n",
      "   [0.4992253  0.70597533 0.833224   ... 0.84891756 0.46331493\n",
      "    0.24515508]\n",
      "   [0.32499123 0.23826496 0.42213779 ... 0.71624667 0.56009592\n",
      "    0.89721235]\n",
      "   ...\n",
      "   [0.93867571 0.33679548 0.40621687 ... 0.99900876 0.75886337\n",
      "    0.33454515]\n",
      "   [0.84813525 0.33924802 0.41415356 ... 0.75297494 0.47507855\n",
      "    0.34239167]\n",
      "   [0.91761885 0.05818462 0.7786409  ... 0.51179637 0.92659656\n",
      "    0.82632233]]]\n",
      "\n",
      "\n",
      " [[[0.95286997 0.93804661 0.60057845 ... 0.91986013 0.82461148\n",
      "    0.29591387]\n",
      "   [0.4992253  0.87139789 0.35257076 ... 0.68837401 0.46331493\n",
      "    0.15679338]\n",
      "   [0.34504066 0.66527306 0.42213779 ... 0.71624667 0.56009592\n",
      "    0.55659487]\n",
      "   ...\n",
      "   [0.93867571 0.81953452 0.40621687 ... 0.99900876 0.71025402\n",
      "    0.97834668]\n",
      "   [0.84813525 0.21215013 0.33839715 ... 0.89873482 0.47507855\n",
      "    0.30614768]\n",
      "   [0.97315575 0.63260573 0.70107587 ... 0.51179637 0.92659656\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.67128284 0.82341921 0.60057845 ... 0.91986013 0.82461148\n",
      "    0.67228262]\n",
      "   [0.4992253  0.92355092 0.88894456 ... 0.68837401 0.46331493\n",
      "    0.72889808]\n",
      "   [0.42814919 0.93787826 0.42213779 ... 0.71624667 0.56009592\n",
      "    0.95338338]\n",
      "   ...\n",
      "   [0.9673488  0.91696839 0.56505005 ... 0.99900876 0.71025402\n",
      "    0.58901491]\n",
      "   [0.84813525 0.91095026 0.4011514  ... 0.75297494 0.78481914\n",
      "    0.34571812]\n",
      "   [0.45323572 0.47433451 0.73259223 ... 0.51179637 0.92659656\n",
      "    0.82632233]]\n",
      "\n",
      "  [[0.67128284 0.5545453  0.60057845 ... 0.91986013 0.82461148\n",
      "    0.42865714]\n",
      "   [0.73207764 0.73214843 0.85891058 ... 0.68837401 0.52081247\n",
      "    0.89545711]\n",
      "   [0.32499123 0.23826496 0.80199523 ... 0.71624667 0.56009592\n",
      "    0.55659487]\n",
      "   ...\n",
      "   [0.93867571 0.33679548 0.76251234 ... 0.99900876 0.71025402\n",
      "    0.34685275]\n",
      "   [0.84813525 0.08008616 0.23263267 ... 0.75297494 0.90440897\n",
      "    0.96420804]\n",
      "   [0.21123052 0.86933678 0.70107587 ... 0.51179637 0.92659656\n",
      "    0.92510001]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)#np.maximum：(X, Y, out=None)X 與Y 逐位比較取其大者；最少接收兩個參數\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed3a0b",
   "metadata": {},
   "source": [
    "# Tensor product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "51231672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6944645  0.2648463  0.3036786  0.00957724 0.4020037 ]\n",
      "[0.2830396  0.65761976 0.99135812 0.91244212 0.55879331]\n",
      "0.9051590140413859\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random((5,))#隨機產生1*5矩陣大小ㄉ的0-1浮點數\n",
    "print(x)\n",
    "y = np.random.random((5,))\n",
    "print(y)\n",
    "z = np.dot(x, y)#矩陣向量內積\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "292cf9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):#向量內積函式（x,y是向量）\n",
    "    assert len(x.shape) == 1#兩個向量之間的點積是一個標量，而且只有元素個數相同的向量之間才能做點積\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "473d2a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):#可以對一個矩陣x 和一個向量y 做點積，返回值是一個向量，其中每個元素是y 和x 的每一行之間的點積\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49a05d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):#零矩陣\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0978798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a0c112",
   "metadata": {},
   "source": [
    "# Tensor reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ddc9bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff4ca183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48cad852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))#讓張量排列方式改變而已\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "171c6a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)#轉置矩陣\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eeadb4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(0.)\n",
    "#with tf.GradientTape() as tape: 其內部發生的tensor操作都會被記錄下來，\n",
    "#可以在其外部通過tape.gradient(y, x)方法獲取因變量y相對於自變量x的梯度。其中自變量可以是單個variable,\n",
    "#也可以是一個variable的列表，variable可以是scalar, 也可以是高維張量.\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "print(grad_of_y_wrt_x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2b7d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(tf.random.uniform((2, 2)))#均勻分佈抽樣得到形狀（2,2）的矩陣\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74a460cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2, 2))#x是tensor非variable\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])#[y對w的導數,y對b的導數]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74bb9749",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e7c8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ea3f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6730790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2556 - accuracy: 0.9258\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1022 - accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0676 - accuracy: 0.9799\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0490 - accuracy: 0.9857\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0376 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4a2a81fc0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09ca8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd03e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "           x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "       weights = []\n",
    "       for layer in self.layers:\n",
    "           weights += layer.weights\n",
    "       return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "682ea84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveSequential([\n",
    "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "])\n",
    "assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e2e4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70dada64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images_batch)\n",
    "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            labels_batch, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cae0a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5db510b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "49334658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs, batch_size=128):\n",
    "    for epoch_counter in range(epochs):\n",
    "        print(f\"Epoch {epoch_counter}\")\n",
    "        batch_generator = BatchGenerator(images, labels)\n",
    "        for batch_counter in range(batch_generator.num_batches):\n",
    "            images_batch, labels_batch = batch_generator.next()\n",
    "            loss = one_training_step(model, images_batch, labels_batch)\n",
    "            if batch_counter % 100 == 0:\n",
    "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "678c8938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss at batch 0: 7.00\n",
      "loss at batch 100: 2.24\n",
      "loss at batch 200: 2.25\n",
      "loss at batch 300: 2.09\n",
      "loss at batch 400: 2.25\n",
      "Epoch 1\n",
      "loss at batch 0: 1.92\n",
      "loss at batch 100: 1.87\n",
      "loss at batch 200: 1.86\n",
      "loss at batch 300: 1.72\n",
      "loss at batch 400: 1.85\n",
      "Epoch 2\n",
      "loss at batch 0: 1.59\n",
      "loss at batch 100: 1.57\n",
      "loss at batch 200: 1.52\n",
      "loss at batch 300: 1.41\n",
      "loss at batch 400: 1.52\n",
      "Epoch 3\n",
      "loss at batch 0: 1.33\n",
      "loss at batch 100: 1.32\n",
      "loss at batch 200: 1.25\n",
      "loss at batch 300: 1.19\n",
      "loss at batch 400: 1.28\n",
      "Epoch 4\n",
      "loss at batch 0: 1.13\n",
      "loss at batch 100: 1.13\n",
      "loss at batch 200: 1.05\n",
      "loss at batch 300: 1.03\n",
      "loss at batch 400: 1.11\n",
      "Epoch 5\n",
      "loss at batch 0: 0.98\n",
      "loss at batch 100: 0.99\n",
      "loss at batch 200: 0.91\n",
      "loss at batch 300: 0.91\n",
      "loss at batch 400: 0.98\n",
      "Epoch 6\n",
      "loss at batch 0: 0.87\n",
      "loss at batch 100: 0.89\n",
      "loss at batch 200: 0.80\n",
      "loss at batch 300: 0.82\n",
      "loss at batch 400: 0.89\n",
      "Epoch 7\n",
      "loss at batch 0: 0.79\n",
      "loss at batch 100: 0.80\n",
      "loss at batch 200: 0.73\n",
      "loss at batch 300: 0.75\n",
      "loss at batch 400: 0.83\n",
      "Epoch 8\n",
      "loss at batch 0: 0.73\n",
      "loss at batch 100: 0.74\n",
      "loss at batch 200: 0.66\n",
      "loss at batch 300: 0.70\n",
      "loss at batch 400: 0.77\n",
      "Epoch 9\n",
      "loss at batch 0: 0.68\n",
      "loss at batch 100: 0.68\n",
      "loss at batch 200: 0.61\n",
      "loss at batch 300: 0.65\n",
      "loss at batch 400: 0.73\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f78eaf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1dd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
