{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 09:39:09.896187: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.01852956,  0.28220034, -0.25650907, -0.18070963, -0.08031923,\n",
       "          0.10321805,  0.13779736,  0.00197354,  0.0530692 ,  0.12021914,\n",
       "         -0.18377078, -0.1456858 , -0.27621293, -0.05630025, -0.22050822,\n",
       "         -0.03359407, -0.04842994,  0.05380523, -0.20545006,  0.06137791,\n",
       "         -0.28962982, -0.10309924,  0.1663244 ,  0.00540349,  0.17367327,\n",
       "         -0.21263874, -0.25551063,  0.29597396, -0.23405431, -0.23542404,\n",
       "         -0.22408715, -0.2060543 , -0.03544739,  0.20287192,  0.29846305,\n",
       "         -0.2978089 , -0.07789077,  0.17079961, -0.08491515, -0.23420914,\n",
       "          0.18027169,  0.01285318,  0.06093791, -0.0463607 , -0.24742562,\n",
       "          0.23027891,  0.19461289,  0.11929569,  0.14352307, -0.02631977,\n",
       "          0.265123  , -0.2149432 , -0.13968499,  0.03647289,  0.13613597,\n",
       "         -0.14641812, -0.09384613, -0.00950825, -0.23832181, -0.14016017,\n",
       "          0.15247294, -0.27937448,  0.07317078, -0.28468522],\n",
       "        [-0.17128348,  0.11820272, -0.13502023,  0.18313766, -0.17179634,\n",
       "          0.09146506, -0.11334139, -0.06938103,  0.13951853, -0.18407594,\n",
       "         -0.22328985,  0.17144603,  0.18348917,  0.12906492, -0.21267563,\n",
       "          0.23903036,  0.2545992 , -0.05252662, -0.25582397,  0.09723955,\n",
       "         -0.26569253, -0.22974014, -0.23265955, -0.1314861 , -0.13079897,\n",
       "          0.11271659,  0.04986387, -0.18589187, -0.19534348, -0.27389172,\n",
       "         -0.23987213, -0.28962904,  0.06665462, -0.17025408,  0.23420537,\n",
       "         -0.26156247, -0.1517183 , -0.02604017, -0.13705884,  0.1321263 ,\n",
       "         -0.13182336,  0.02624273, -0.05467561, -0.28671128,  0.07843864,\n",
       "         -0.27375153, -0.2154713 ,  0.23641694, -0.19720921,  0.1684171 ,\n",
       "         -0.26882434,  0.08636627,  0.12517971, -0.07420596, -0.27548128,\n",
       "          0.17501745, -0.06059659,  0.16042739, -0.06184959, -0.20163561,\n",
       "          0.13418552, -0.08056994,  0.01852843,  0.2842062 ],\n",
       "        [-0.02688777, -0.14962776,  0.19731224,  0.07151723,  0.13878259,\n",
       "          0.06403759,  0.18811762, -0.22498855, -0.11948839, -0.09329604,\n",
       "          0.17282352, -0.28349152,  0.26794767, -0.05839181, -0.05155744,\n",
       "         -0.07053028, -0.29374322,  0.00798705,  0.07338876,  0.22448337,\n",
       "          0.08450675, -0.22560193, -0.18586776,  0.10395429,  0.09278163,\n",
       "         -0.27774063, -0.1915769 , -0.16409025,  0.06703356, -0.044857  ,\n",
       "         -0.19882402,  0.13917357, -0.22512183, -0.19281721, -0.17247976,\n",
       "          0.0890871 , -0.11706558,  0.10670742, -0.24401034, -0.24931738,\n",
       "          0.17816895,  0.2802056 ,  0.09816894,  0.19057876, -0.05885935,\n",
       "          0.14642054,  0.22569203, -0.22247612,  0.25907433, -0.15840556,\n",
       "         -0.12737522, -0.13637368,  0.12547067, -0.1898827 , -0.15476713,\n",
       "         -0.27478662, -0.26932013, -0.02095196, -0.11875322, -0.05243514,\n",
       "          0.03254536,  0.11481577,  0.19377697, -0.12081924]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-0.07203057,  0.25717816, -0.23427472, -0.13736512,  0.24033394,\n",
       "          0.12482798, -0.16112432, -0.03404331,  0.2142308 , -0.14199433],\n",
       "        [ 0.0183143 , -0.05462524,  0.18468311,  0.21545824,  0.05012006,\n",
       "         -0.06968555,  0.1285525 ,  0.02923289,  0.19589737,  0.19229952],\n",
       "        [ 0.12574053, -0.1640407 ,  0.1740574 , -0.17445353,  0.20393774,\n",
       "         -0.24678403,  0.26497015,  0.17112872, -0.2803885 , -0.00029972],\n",
       "        [-0.26024792, -0.26439044, -0.11169313, -0.2478672 ,  0.14154258,\n",
       "          0.09881756,  0.22830686, -0.01292202,  0.28007397, -0.15453996],\n",
       "        [-0.08967413, -0.27589786,  0.25146148,  0.13218871, -0.06614915,\n",
       "          0.20719433,  0.13684785, -0.01743099,  0.10215858, -0.26480776],\n",
       "        [ 0.02645183, -0.07269914, -0.20559464,  0.27087662, -0.10806488,\n",
       "          0.24746409, -0.16904405,  0.00765592, -0.12689947, -0.21982989],\n",
       "        [-0.17378774, -0.2032283 ,  0.18529338,  0.28468207,  0.26340845,\n",
       "          0.21569303, -0.1975874 ,  0.13759086, -0.07509637,  0.20622417],\n",
       "        [ 0.0933066 ,  0.28384534,  0.089304  , -0.05676273, -0.08405189,\n",
       "         -0.21853118,  0.01102859, -0.2335961 ,  0.27131715, -0.2121545 ],\n",
       "        [ 0.09177402,  0.18162009, -0.23559761, -0.15713128,  0.06852525,\n",
       "         -0.19441888,  0.22569236, -0.12686029,  0.2386935 ,  0.01579976],\n",
       "        [ 0.1822975 ,  0.16733643,  0.03005388, -0.03903446, -0.17254868,\n",
       "          0.24902996,  0.25337055,  0.26835224, -0.07251789,  0.18400171],\n",
       "        [-0.23276304,  0.15895098,  0.19663933, -0.08763541,  0.17108786,\n",
       "          0.00841987,  0.23683509, -0.16887182, -0.2578496 ,  0.16494578],\n",
       "        [-0.22411764, -0.18824913, -0.14883606,  0.01867661, -0.03722066,\n",
       "          0.11292505, -0.17262968, -0.17767818, -0.1803008 , -0.04877409],\n",
       "        [-0.11669867, -0.06210132, -0.11355105, -0.2587498 , -0.20142259,\n",
       "         -0.09090678, -0.05266868, -0.21969473,  0.07931602,  0.27741793],\n",
       "        [-0.0323461 , -0.23267743,  0.18794897,  0.01469514,  0.05007288,\n",
       "          0.22240016,  0.23582736, -0.08315623,  0.0152007 ,  0.15082324],\n",
       "        [ 0.0618768 ,  0.07497826,  0.08019492,  0.23540285,  0.03478289,\n",
       "         -0.02401215,  0.13477847, -0.15032046,  0.14523861, -0.23767745],\n",
       "        [-0.22738357, -0.00796258, -0.09697464, -0.05274172, -0.01448441,\n",
       "          0.22701654,  0.16168264,  0.11099821, -0.08846223,  0.15422964],\n",
       "        [ 0.27392784,  0.09101167, -0.15680169, -0.28049904, -0.04306795,\n",
       "         -0.16379562,  0.14486936, -0.22608629, -0.25971705,  0.10066   ],\n",
       "        [-0.15901059,  0.12498093,  0.0744164 , -0.23452836,  0.08231816,\n",
       "          0.02259687,  0.05263597, -0.26936916, -0.14432979, -0.20910111],\n",
       "        [-0.01333925,  0.16145909, -0.27073285, -0.01218086,  0.03867829,\n",
       "         -0.24310696,  0.16279623,  0.07977107, -0.02809229,  0.16090226],\n",
       "        [ 0.24881676, -0.0719859 , -0.2718689 , -0.2666765 , -0.11820003,\n",
       "          0.08840692, -0.1434109 ,  0.2371805 ,  0.26466522, -0.10097665],\n",
       "        [ 0.21609607, -0.07558423, -0.15700786,  0.23066363, -0.10697851,\n",
       "          0.19525114,  0.25885007, -0.19910505, -0.27884138, -0.05779091],\n",
       "        [-0.14222854,  0.12833628,  0.03271079,  0.20888197, -0.10759284,\n",
       "         -0.2828524 ,  0.21803334,  0.10908782,  0.01766792,  0.02264163],\n",
       "        [-0.18890995, -0.21941638, -0.07168087, -0.07189819, -0.04186611,\n",
       "         -0.23898086,  0.12103277,  0.12490794,  0.05413201, -0.21078259],\n",
       "        [ 0.12339741, -0.21286115, -0.26363635,  0.13068047, -0.17442243,\n",
       "         -0.17347172,  0.13296232, -0.08169751,  0.05890509,  0.09270102],\n",
       "        [-0.09025492, -0.17972994,  0.21348974,  0.12852189, -0.16063008,\n",
       "          0.24568143,  0.21004614,  0.2057952 , -0.18334156, -0.23882994],\n",
       "        [ 0.2678534 ,  0.08087298, -0.09080279, -0.21786125,  0.01501399,\n",
       "          0.16667092,  0.22530004,  0.2674211 ,  0.28277817, -0.22403637],\n",
       "        [ 0.25484553, -0.07232392,  0.14773944, -0.23146792,  0.07562992,\n",
       "          0.19893175, -0.10999815,  0.13280684,  0.20976302, -0.27607253],\n",
       "        [ 0.15918073,  0.13926363, -0.02283618,  0.1763561 , -0.1981794 ,\n",
       "          0.06695655, -0.01216632, -0.24231312, -0.07525462, -0.14315456],\n",
       "        [ 0.13123268,  0.26587543, -0.12077282, -0.26053992, -0.25191793,\n",
       "         -0.14090452, -0.00899163,  0.18824437, -0.27405962,  0.20833316],\n",
       "        [-0.04798657, -0.12642872, -0.19849378, -0.01487938, -0.26708707,\n",
       "          0.1149489 , -0.02271882, -0.19093   , -0.0807884 , -0.11229944],\n",
       "        [-0.09482345, -0.01997337,  0.23116878,  0.05433154, -0.01327822,\n",
       "          0.04441458, -0.02224237,  0.06113362,  0.28116903, -0.13340446],\n",
       "        [ 0.2491661 , -0.0087471 , -0.16821988, -0.17868097,  0.14544705,\n",
       "          0.24706319,  0.2573553 , -0.01236606,  0.03061736,  0.05397359],\n",
       "        [-0.01448074,  0.1313889 , -0.03816615, -0.08446494, -0.09279044,\n",
       "         -0.17088704,  0.12922087,  0.00858891,  0.11601725, -0.12513775],\n",
       "        [-0.26896   , -0.06451477,  0.08987045,  0.13978508, -0.23523752,\n",
       "         -0.15020335, -0.20321622, -0.04967864, -0.23091611, -0.14814529],\n",
       "        [ 0.2510964 ,  0.09373832,  0.18436676, -0.07772259,  0.24190977,\n",
       "         -0.26958296, -0.00737342, -0.15575735,  0.19663364, -0.17240205],\n",
       "        [ 0.11063012,  0.27300158, -0.04433252, -0.11225545, -0.02652699,\n",
       "         -0.26112133, -0.03892522, -0.27219227,  0.03178886,  0.10645583],\n",
       "        [-0.22716932,  0.16956756, -0.25927764,  0.03776494, -0.13868271,\n",
       "          0.09722304,  0.23040232,  0.25164428,  0.02944723, -0.23993002],\n",
       "        [-0.2748187 , -0.01539826,  0.03108314,  0.02041772,  0.10453641,\n",
       "         -0.17622766, -0.22519416,  0.23997095,  0.22601113,  0.05759022],\n",
       "        [-0.26742455, -0.22916688, -0.16346452, -0.21247602, -0.03160331,\n",
       "         -0.19715664, -0.00259641,  0.0039345 ,  0.265295  ,  0.02012557],\n",
       "        [ 0.23220167, -0.1217604 ,  0.13317826,  0.11732072, -0.15989837,\n",
       "         -0.09092715, -0.02734932,  0.28000525, -0.16450547,  0.27061722],\n",
       "        [-0.12246495, -0.05053553,  0.23502985, -0.10126843, -0.04311262,\n",
       "          0.13434601,  0.22002807, -0.02422372,  0.0991866 , -0.06276311],\n",
       "        [-0.24528131,  0.16446418,  0.20218241,  0.23509184,  0.05448931,\n",
       "         -0.12697177,  0.19640905, -0.07615185,  0.02054906,  0.14904496],\n",
       "        [-0.05111958,  0.23744574, -0.13490915, -0.05520637, -0.27175206,\n",
       "         -0.12134466,  0.19314441,  0.13799235,  0.01358807, -0.01585013],\n",
       "        [ 0.00624546, -0.08254285,  0.0766803 ,  0.26091996, -0.22906579,\n",
       "         -0.07126221,  0.08130592,  0.19588888,  0.23062971, -0.12140201],\n",
       "        [-0.13206318, -0.19185804, -0.0415792 , -0.18665442, -0.25401074,\n",
       "         -0.15623508, -0.1414227 ,  0.00087795,  0.13412184, -0.2792739 ],\n",
       "        [ 0.1758754 ,  0.02273762,  0.06985167, -0.16745076,  0.06433004,\n",
       "          0.12269768, -0.18022451, -0.13157722,  0.19627571,  0.00841552],\n",
       "        [-0.14743143,  0.02903569, -0.20824496, -0.10523485, -0.23861915,\n",
       "          0.27015015, -0.08593833,  0.05495694,  0.24727139, -0.2508757 ],\n",
       "        [-0.1677864 , -0.11220767, -0.14631242, -0.1962874 , -0.08581932,\n",
       "          0.02761346,  0.13413972, -0.22857672,  0.00657642, -0.16331157],\n",
       "        [ 0.02960309,  0.27972534,  0.05167499, -0.12547237,  0.07223228,\n",
       "         -0.06272441, -0.03490095,  0.1767604 , -0.02590939,  0.25672373],\n",
       "        [ 0.25043216, -0.15875594,  0.24055925,  0.2732711 ,  0.23879543,\n",
       "         -0.14761372,  0.10760084, -0.04285172,  0.08051774,  0.2086961 ],\n",
       "        [-0.02146646, -0.16798003, -0.09684837, -0.1222169 , -0.17359404,\n",
       "         -0.07857589, -0.20056638,  0.22847286, -0.23047952,  0.10257876],\n",
       "        [-0.02681366,  0.05635574, -0.05482177, -0.20506538,  0.1999915 ,\n",
       "          0.22880074,  0.11536193,  0.18357   , -0.04282904,  0.15103945],\n",
       "        [ 0.03578073,  0.25188568, -0.2734738 , -0.06354804, -0.24358252,\n",
       "          0.04627347,  0.14449325, -0.16428693, -0.01232567, -0.2673707 ],\n",
       "        [ 0.1162582 , -0.0830709 ,  0.18874303,  0.17453486, -0.03239802,\n",
       "         -0.19159673, -0.04238376,  0.02396825,  0.17147061,  0.1098752 ],\n",
       "        [-0.21684277, -0.01836881,  0.21997938,  0.21248206, -0.05558485,\n",
       "         -0.14204043, -0.02504814,  0.16181761, -0.15771621, -0.14759064],\n",
       "        [-0.06538932,  0.21685031, -0.1986961 ,  0.24623951, -0.23884508,\n",
       "          0.08689564,  0.20775282, -0.13338783,  0.12766275,  0.12325695],\n",
       "        [-0.25870487, -0.12359436,  0.17940548, -0.22573155,  0.04097146,\n",
       "         -0.17574844, -0.02715433, -0.0975458 , -0.25270462,  0.24735436],\n",
       "        [-0.1849624 , -0.25147074, -0.02198192, -0.1536591 ,  0.18024799,\n",
       "          0.15214944,  0.22491065,  0.06268808, -0.21339965, -0.03893438],\n",
       "        [-0.25471374, -0.00734994, -0.12276679,  0.11421731,  0.08272621,\n",
       "         -0.11061125, -0.13808413, -0.15668859,  0.22715667,  0.14625749],\n",
       "        [-0.1365203 , -0.00522888, -0.18884423, -0.21609879, -0.0386157 ,\n",
       "         -0.13666734,  0.00206676,  0.17568943,  0.26226076,  0.19875842],\n",
       "        [-0.10581027, -0.12079461, -0.2033911 ,  0.26630613, -0.09857948,\n",
       "         -0.03075165, -0.17348862,  0.2344015 , -0.21801257, -0.25239906],\n",
       "        [-0.06034672, -0.2010025 ,  0.21532008,  0.27912155, -0.09950942,\n",
       "          0.2166138 , -0.27554673, -0.06087871, -0.02057019, -0.0198974 ],\n",
       "        [-0.07089376, -0.12784076,  0.12818074,  0.03333101, -0.1755845 ,\n",
       "          0.2061227 ,  0.18833983, -0.18046035, -0.12589878,  0.266295  ],\n",
       "        [-0.22109039,  0.1546849 , -0.20856662, -0.2559917 ,  0.12034357,\n",
       "          0.04792914, -0.22183344,  0.08013034, -0.01689529,  0.26614395]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 6ms/step - loss: 33.9061 - priority_loss: 0.3258 - department_loss: 33.5803 - priority_mean_absolute_error: 0.4894 - department_accuracy: 0.2352\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 21.6423 - priority_loss: 0.3285 - department_loss: 21.3138 - priority_mean_absolute_error: 0.4923 - department_accuracy: 0.0633\n",
      "40/40 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 6ms/step - loss: 40.9657 - priority_loss: 0.3285 - department_loss: 40.6372 - priority_mean_absolute_error: 0.4923 - department_accuracy: 0.2500\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 36.0209 - priority_loss: 0.3285 - department_loss: 35.6924 - priority_mean_absolute_error: 0.4923 - department_accuracy: 0.5758\n",
      "40/40 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7fb25d177fd0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7fb25d1901f0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7fb25d191cc0>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x7fb25d174cd0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fb25d1927a0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fb25d192530>,\n",
       " <keras.layers.core.dense.Dense at 0x7fb25d192bf0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 6ms/step - loss: 30.9617 - output_1_loss: 0.3237 - output_2_loss: 30.6379 - output_1_mean_absolute_error: 0.4880 - output_2_accuracy: 0.2414\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 24.1405 - output_1_loss: 0.3285 - output_2_loss: 23.8119 - output_1_mean_absolute_error: 0.4923 - output_2_accuracy: 0.1242\n",
      "40/40 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2942 - accuracy: 0.9116 - val_loss: 0.1438 - val_accuracy: 0.9584\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1662 - accuracy: 0.9531 - val_loss: 0.1165 - val_accuracy: 0.9682\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1396 - accuracy: 0.9623 - val_loss: 0.1121 - val_accuracy: 0.9706\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1084 - accuracy: 0.9711\n",
      "313/313 [==============================] - 0s 999us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2924 - accuracy: 0.9129 - rmse: 7.1808 - val_loss: 0.1513 - val_accuracy: 0.9559 - val_rmse: 7.3665\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1660 - accuracy: 0.9534 - rmse: 7.3527 - val_loss: 0.1233 - val_accuracy: 0.9667 - val_rmse: 7.4053\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1389 - accuracy: 0.9627 - rmse: 7.3865 - val_loss: 0.1156 - val_accuracy: 0.9710 - val_rmse: 7.4227\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1068 - accuracy: 0.9710 - rmse: 7.4345\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.2936 - accuracy: 0.9136 - val_loss: 0.1621 - val_accuracy: 0.9537\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1645 - accuracy: 0.9543 - val_loss: 0.1323 - val_accuracy: 0.9653\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1404 - accuracy: 0.9627 - val_loss: 0.1177 - val_accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1261 - accuracy: 0.9683 - val_loss: 0.1065 - val_accuracy: 0.9741\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1154 - accuracy: 0.9712 - val_loss: 0.1119 - val_accuracy: 0.9744\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1103 - accuracy: 0.9737 - val_loss: 0.1017 - val_accuracy: 0.9758\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1092 - accuracy: 0.9744 - val_loss: 0.1048 - val_accuracy: 0.9766\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0979 - accuracy: 0.9768 - val_loss: 0.1129 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0978 - accuracy: 0.9772 - val_loss: 0.1149 - val_accuracy: 0.9782\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0930 - accuracy: 0.9788 - val_loss: 0.1187 - val_accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb25d1b04f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2969 - accuracy: 0.9116 - val_loss: 0.1455 - val_accuracy: 0.9582\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1669 - accuracy: 0.9534 - val_loss: 0.1206 - val_accuracy: 0.9673\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1399 - accuracy: 0.9631 - val_loss: 0.1119 - val_accuracy: 0.9709\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1266 - accuracy: 0.9664 - val_loss: 0.1099 - val_accuracy: 0.9727\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1194 - accuracy: 0.9703 - val_loss: 0.1097 - val_accuracy: 0.9744\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1086 - accuracy: 0.9728 - val_loss: 0.1087 - val_accuracy: 0.9760\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1059 - accuracy: 0.9742 - val_loss: 0.1061 - val_accuracy: 0.9768\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1031 - accuracy: 0.9763 - val_loss: 0.1019 - val_accuracy: 0.9781\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0968 - accuracy: 0.9781 - val_loss: 0.1134 - val_accuracy: 0.9783\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0962 - accuracy: 0.9786 - val_loss: 0.1084 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb25ec1afb0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 09:44:09.833021: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at summary_kernels.cc:65 : PERMISSION_DENIED: /full_path_to_your_log_dir; Read-only file system\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "/full_path_to_your_log_dir; Read-only file system [Op:CreateSummaryFileWriter]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m tensorboard \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(\n\u001b[1;32m      7\u001b[0m     log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/full_path_to_your_log_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: /full_path_to_your_log_dir; Read-only file system [Op:CreateSummaryFileWriter]"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4b3350509f9e09a4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4b3350509f9e09a4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9147\n",
      "...loss: 0.2908\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9538\n",
      "...loss: 0.1670\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9620\n",
      "...loss: 0.1420\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9672\n",
      "...val_loss: 0.1355\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9672\n",
      "...val_loss: 0.1355\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2918\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1639\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb25f97a140>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2947 - sparse_categorical_accuracy: 0.9119\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1648 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1384 - sparse_categorical_accuracy: 0.9623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb25f9b86a0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
